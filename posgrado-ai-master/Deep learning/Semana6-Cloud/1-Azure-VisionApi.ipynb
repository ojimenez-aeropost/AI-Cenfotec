{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debe Crear un Computer Vision Resource en Azure.\n",
    "# Aqui es donde obtiene el API Key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/azure1.PNG\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade azure-cognitiveservices-vision-computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = \"fbe1d5efa54f4665b81095d3f1a2f56f\"\n",
    "endpoint = \"https://visionjuanzamoraresource.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autenticacion del cliente de azure.\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar Imagen Remota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/landmark.jpg\"\n",
    "\n",
    "image = io.imread(remote_image_url)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener Descripcion de la Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Describe an Image - remote\n",
    "This example describes the contents of an image with the confidence score.\n",
    "'''\n",
    "print(\"===== Describe an image - remote =====\")\n",
    "# Call API\n",
    "description_results = computervision_client.describe_image(remote_image_url )\n",
    "\n",
    "# Get the captions (descriptions) from the response, with confidence level\n",
    "print(\"Description of remote image: \")\n",
    "if (len(description_results.captions) == 0):\n",
    "    print(\"No description detected.\")\n",
    "else:\n",
    "    for caption in description_results.captions:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categoria de la Imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Categorize an Image - remote\n",
    "This example extracts (general) categories from a remote image with a confidence score.\n",
    "'''\n",
    "print(\"===== Categorize an image - remote =====\")\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"categories\"]\n",
    "# Call API with URL and features\n",
    "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Categories from remote image: \")\n",
    "if (len(categorize_results_remote.categories) == 0):\n",
    "    print(\"No categories detected.\")\n",
    "else:\n",
    "    for category in categorize_results_remote.categories:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags (etiquetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tag an Image - remote\n",
    "This example returns a tag (key word) for each thing in the image.\n",
    "'''\n",
    "print(\"===== Tag an image - remote =====\")\n",
    "# Call API with remote image\n",
    "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
    "\n",
    "# Print results with confidence score\n",
    "print(\"Tags in the remote image: \")\n",
    "if (len(tags_result_remote.tags) == 0):\n",
    "    print(\"No tags detected.\")\n",
    "else:\n",
    "    for tag in tags_result_remote.tags:\n",
    "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deteccion de Objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect Objects - remote\n",
    "This example detects different kinds of objects with bounding boxes in a remote image.\n",
    "'''\n",
    "print(\"===== Detect Objects - remote =====\")\n",
    "# Get URL image with different objects\n",
    "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
    "# Call API with URL\n",
    "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
    "\n",
    "# Print detected objects results with bounding boxes\n",
    "print(\"Detecting objects in remote image:\")\n",
    "if len(detect_objects_results_remote.objects) == 0:\n",
    "    print(\"No objects detected.\")\n",
    "else:\n",
    "    for object in detect_objects_results_remote.objects:\n",
    "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
    "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
    "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(detect_objects_results_remote.objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detectar Marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/images/gray-shirt-logo.jpg\"\n",
    "\n",
    "image = io.imread(remote_image_url)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect Brands - remote\n",
    "This example detects common brands like logos and puts a bounding box around them.\n",
    "'''\n",
    "print(\"===== Detect Brands - remote =====\")\n",
    "# Get a URL with a brand logo\n",
    "remote_image_url = \"https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/images/gray-shirt-logo.jpg\"\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"brands\"]\n",
    "# Call API with URL and features\n",
    "detect_brands_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "print(\"Detecting brands in remote image: \")\n",
    "if len(detect_brands_results_remote.brands) == 0:\n",
    "    print(\"No brands detected.\")\n",
    "else:\n",
    "    for brand in detect_brands_results_remote.brands:\n",
    "        print(\"'{}' brand detected with confidence {:.1f}% at location {}, {}, {}, {}\".format( \\\n",
    "        brand.name, brand.confidence * 100, brand.rectangle.x, brand.rectangle.x + brand.rectangle.w, \\\n",
    "        brand.rectangle.y, brand.rectangle.y + brand.rectangle.h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deteccion Facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url_faces = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n",
    "image = io.imread(remote_image_url_faces)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect Faces - remote\n",
    "This example detects faces in a remote image, gets their gender and age, \n",
    "and marks them with a bounding box.\n",
    "'''\n",
    "print(\"===== Detect Faces - remote =====\")\n",
    "# Get an image with faces\n",
    "remote_image_url_faces = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/faces.jpg\"\n",
    "# Select the visual feature(s) you want.\n",
    "remote_image_features = [\"faces\"]\n",
    "# Call the API with remote URL and features\n",
    "detect_faces_results_remote = computervision_client.analyze_image(remote_image_url_faces, remote_image_features)\n",
    "\n",
    "# Print the results with gender, age, and bounding box\n",
    "print(\"Faces in the remote image: \")\n",
    "if (len(detect_faces_results_remote.faces) == 0):\n",
    "    print(\"No faces detected.\")\n",
    "else:\n",
    "    for face in detect_faces_results_remote.faces:\n",
    "        print(\"'{}' of age {} at location {}, {}, {}, {}\".format(face.gender, face.age, \\\n",
    "        face.face_rectangle.left, face.face_rectangle.top, \\\n",
    "        face.face_rectangle.left + face.face_rectangle.width, \\\n",
    "        face.face_rectangle.top + face.face_rectangle.height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido Sensible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url = \"https://www.splcenter.org/sites/default/files/group_images/SPLC-Intelligence-Files-Groups-Brotherhood-of-Klans-1280x720_0.jpg\"\n",
    "image = io.imread(remote_image_url)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect Adult or Racy Content - remote\n",
    "This example detects adult or racy content in a remote image, then prints the adult/racy score.\n",
    "The score is ranged 0.0 - 1.0 with smaller numbers indicating negative results.\n",
    "'''\n",
    "print(\"===== Detect Adult or Racy Content - remote =====\")\n",
    "# Select the visual feature(s) you want\n",
    "remote_image_features = [\"adult\"]\n",
    "# Call API with URL and features\n",
    "detect_adult_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results with adult/racy score\n",
    "print(\"Analyzing remote image for adult or racy content ... \")\n",
    "print(\"Is adult content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_adult_content, detect_adult_results_remote.adult.adult_score))\n",
    "print(\"Has racy content: {} with confidence {:.2f}\".format(detect_adult_results_remote.adult.is_racy_content, detect_adult_results_remote.adult.racy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Color Schema\n",
    "'''\n",
    "Detect Color - remote\n",
    "This example detects the different aspects of its color scheme in a remote image.\n",
    "'''\n",
    "print(\"===== Detect Color - remote =====\")\n",
    "# Select the feature(s) you want\n",
    "remote_image_features = [\"color\"]\n",
    "# Call API with URL and features\n",
    "detect_color_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
    "\n",
    "# Print results of color scheme\n",
    "print(\"Getting color scheme of the remote image: \")\n",
    "print(\"Is black and white: {}\".format(detect_color_results_remote.color.is_bw_img))\n",
    "print(\"Accent color: {}\".format(detect_color_results_remote.color.accent_color))\n",
    "print(\"Dominant background color: {}\".format(detect_color_results_remote.color.dominant_color_background))\n",
    "print(\"Dominant foreground color: {}\".format(detect_color_results_remote.color.dominant_color_foreground))\n",
    "print(\"Dominant colors: {}\".format(detect_color_results_remote.color.dominant_colors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido Especifico sobre un Contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_url_celebs = \"https://i.guim.co.uk/img/media/a23aeb1f7ff20bb80f68852da17743b0e557f8ed/0_224_3504_2102/master/3504.jpg?width=1200&height=1200&quality=85&auto=format&fit=crop&s=9e9a99e479ee60270b69ede4d869b20f\"\n",
    "image = io.imread(remote_image_url_celebs)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect Domain-specific Content - remote\n",
    "This example detects celebrites and landmarks in remote images.\n",
    "'''\n",
    "print(\"===== Detect Domain-specific Content - remote =====\")\n",
    "# Call API with content type (celebrities) and URL\n",
    "detect_domain_results_celebs_remote = computervision_client.analyze_image_by_domain(\"celebrities\", remote_image_url_celebs)\n",
    "\n",
    "# Print detection results with name\n",
    "print(\"Celebrities in the remote image:\")\n",
    "if len(detect_domain_results_celebs_remote.result[\"celebrities\"]) == 0:\n",
    "    print(\"No celebrities detected.\")\n",
    "else:\n",
    "    for celeb in detect_domain_results_celebs_remote.result[\"celebrities\"]:\n",
    "        print(celeb[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info sobre la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect Image Types - remote\n",
    "This example detects an image's type (clip art/line drawing).\n",
    "'''\n",
    "print(\"===== Detect Image Types - remote =====\")\n",
    "# Get URL of an image with a type\n",
    "remote_image_url_type = remote_image_url_celebs\n",
    "# Select visual feature(s) you want\n",
    "remote_image_features = [VisualFeatureTypes.image_type]\n",
    "# Call API with URL and features\n",
    "detect_type_results_remote = computervision_client.analyze_image(remote_image_url_type, remote_image_features)\n",
    "\n",
    "# Prints type results with degree of accuracy\n",
    "print(\"Type of remote image:\")\n",
    "if detect_type_results_remote.image_type.clip_art_type == 0:\n",
    "    print(\"Image is not clip art.\")\n",
    "elif detect_type_results_remote.image_type.line_drawing_type == 1:\n",
    "    print(\"Image is ambiguously clip art.\")\n",
    "elif detect_type_results_remote.image_type.line_drawing_type == 2:\n",
    "    print(\"Image is normal clip art.\")\n",
    "else:\n",
    "    print(\"Image is good clip art.\")\n",
    "\n",
    "if detect_type_results_remote.image_type.line_drawing_type == 0:\n",
    "    print(\"Image is not a line drawing.\")\n",
    "else:\n",
    "    print(\"Image is a line drawing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_image_handw_text_url = \"https://raw.githubusercontent.com/MicrosoftDocs/azure-docs/master/articles/cognitive-services/Computer-vision/Images/readsample.jpg\"\n",
    "image = io.imread(remote_image_handw_text_url)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call API with URL and raw response (allows you to get the operation location)\n",
    "recognize_handw_results = computervision_client.read(remote_image_handw_text_url,  raw=True)\n",
    "\n",
    "# Get the operation location (URL with an ID at the end) from the response\n",
    "operation_location_remote = recognize_handw_results.headers[\"Operation-Location\"]\n",
    "# Grab the ID from the URL\n",
    "operation_id = operation_location_remote.split(\"/\")[-1]\n",
    "\n",
    "# Call the \"GET\" API and wait for it to retrieve the results \n",
    "while True:\n",
    "    get_handw_text_results = computervision_client.get_read_result(operation_id)\n",
    "    if get_handw_text_results.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "if get_handw_text_results.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in get_handw_text_results.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            print(line.bounding_box)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación Gausiana con Bayes\n",
    "\n",
    "Para trabajar con Bayes en machine learning, vamos a definir la nomenclatura de la del teorema de Bayes para que sea más comprensible bajo nuestros estandares de ML. \n",
    "\n",
    "Pordemos re-imaginar la fórmula de la siguiente forma:\n",
    "\n",
    "$$P(clase|datos)=\\frac{P(datos|clase)*P(clase)}{P(datos)}$$\n",
    "\n",
    "Nuestra definición de Bayes sirve igualmente para clasificación binaria, como para clasificación multi-clase. Vamos a utilizar nuestro dataset de Iris para ejemplificar la clasificación multi-clase. \n",
    "\n",
    "Vamos a utilizar los datos directamente de Sklearn. Para simplificar el ejercicio, vamos a utilizar solo 2 features: el largo y el ancho de sépalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "\n",
    "list(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad previa: P(Clase) o P(y = c)\n",
    "\n",
    "Es la probabilidad de una clase es la frecuencia de las instancias de una clase dividido sobre el total de instancias en el dataset.\n",
    "\n",
    "- P(setosa) = # clases setosa / Total de Datos\n",
    "- P(versicolor) = # clases versicolor / Total de Datos\n",
    "- P(virginica) # clases virginica / Total de Datos\n",
    "\n",
    "En este caso todas las clases obtienen una probabilidad de 0.33, porque hay 50 ejemplos de cada tipo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_setosa = np.sum((y == 0) * 1) / len(y)\n",
    "p_versicolor = np.sum((y == 1) * 1) / len(y)\n",
    "p_virginica = np.sum((y == 2) * 1) / len(y)\n",
    "\n",
    "print(\"P(setosa)\",p_setosa)\n",
    "print(\"P(versicolor)\",p_versicolor)\n",
    "print(\"P(virginica)\",p_virginica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad: P(datos|clase) o p(x|y = c) \n",
    "\n",
    "Vamos a hacer una pequena modificacion a nuestra formula, para estimar P(datos|clase) en funcion de una distribucion Gaussiana. Prácticamente asumimos que los datos X pertenes a una distribucion normal que esta descrita por una media y una desviacion estandard obtenida de los datos, para cada clase. La prediccion consta en determinar si los datos x pertenece a una distribucion u a otra. \n",
    "\n",
    "La funcion de densidad gaussiana, también es llamada como Probability Density Function (PDF)\n",
    "\n",
    "La fórmula de densidad Gaussiana estaria definida de la siguiente forma:\n",
    "\n",
    "<img src=\"img/nd.png\" />\n",
    "\n",
    "Ahora, vamos a eliminar el termino normalizador, y vamos a calcular la probabilidad bajo la siguiente definición:\n",
    "\n",
    "<img src=\"img/bayes_g.png\" />\n",
    "\n",
    "Donde ϕ es la función de la densidad Gaussiana. Vamos a ejecutar ϕ(x1|mu,sig)*p(y) por cada clase y (osea tres veces). Vamos a seleccionar la probabilidad más alta de los 3 cálculos. Esa probabilidad, sera de la clase más probable.\n",
    "\n",
    "El metodo predecir que tenemos abajo, usa la funcion *norm.PDF* de la librería scipy.stats que implementa la función gaussiana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a crear un dataframe para genenrar un mejor filtrado de las medias y varianzas de cada clase\n",
    "df = pd.DataFrame({\"largo_sepalo\": X[:,0], \"ancho_sepalo\": X[:,1], \"clase\": y})\n",
    "\n",
    "# caculamos la media, desviacion estandard de cada feature xi segun la clase\n",
    "medias = np.split(df.groupby('clase').mean().values,[1,2])\n",
    "desviaciones = np.split(df.groupby('clase').std().values,[1,2], axis = 0)\n",
    "\n",
    "# generamos el arreglo de las probabilidades previas\n",
    "prob_clases = np.array([p_setosa, p_versicolor, p_virginica])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecir(x_,medias_,desviaciones_,probs_): \n",
    "    scores = []\n",
    "    num_clases = len(probs_)\n",
    "    \n",
    "    # ϕ(x1|mu,sig)*p(y) * ϕ(x1|mu,sig)*p(y) * ϕ(x1|mu,sig)*p(y)\n",
    "    for p in range(num_clases):\n",
    "        valor = (norm.pdf(x = x_[0], loc = medias_[p][0][0], scale = desviaciones_[p][0][0] )  \n",
    "                * norm.pdf(x = x_[1], loc = medias_[p][0][1], scale = desviaciones_[p][0][1] ) \n",
    "                * probs_[p])\n",
    "        \n",
    "        scores.append(valor)\n",
    "             \n",
    "    return np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prima = predecir([5.1,3.5], medias, desviaciones, prob_clases)\n",
    "print(\"una planta con los valores 5.1,3.5, pertencen a la clase\", iris.target_names[y_prima])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predecir todo el dataset\n",
    "\n",
    "y_prima = [predecir(x, medias, desviaciones, prob_clases) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a ver el accuracy de la prediccion.\n",
    "acc = accuracy_score(y, y_prima)\n",
    "\n",
    "print(\"La exactitud de la predicción es de:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

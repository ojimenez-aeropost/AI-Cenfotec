{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling (Remuestreo)\n",
    "\n",
    "El remuestreo es una metodología de uso económico de una muestra de datos para mejorar la precisión y cuantificar la incertidumbre de un parámetro de población.\n",
    "\n",
    "El remuestreo es una herramienta que nos permite:\n",
    "\n",
    "- Seleccionar una muestra de una población. \n",
    "- entrenar un modelo contra la muestra.\n",
    "- verificar el rendimiento del modelo.\n",
    "\n",
    "El remuestreo ha sido considerado como una tarea “computacionalmente costosa”, sin embargo con los recursos computacionales disponibles, cada vez se hace más factible ejecutarlo tanto en “commodity laptops” como en el “cloud”.\n",
    "\n",
    "Existen diversas técnicas, sin embargo las más populares son:\n",
    "\n",
    "- Selección aleatoria\n",
    "- Validación Cruzada (Cross-Validation)\n",
    "- Bootstrap\n",
    "\n",
    "A continuación, vamos a ver como se puede utilizar cada uno de estos métodos, para la evaluación de modelos de aprendizaje automático. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección Aleatoria\n",
    "\n",
    "La selección aleatoria busca dividir el dataset en dos partes: el set de entrenamiento (training set) y un set de pruebas (test set). \n",
    "\n",
    "Esta técnica es particularmente útil y rápida de ejecutar en donde se definen una partición de los datos para entrenamiento y otra para prueba. Normalmente se escoge una muestra del 80% de los datos para entrenar el modelo y un 20% para probarlos. Estos porcentajes pueden variar dependiendo del tamaño del dataset. \n",
    "\n",
    "Existe un inconveniente respecto a la selección de una única muestra aleatoria; está reside en que los valores que queden tanto en el training set como en el test set no sean verdaderamente representativos de la población.\n",
    "\n",
    "Para este notebook vamos a utilizar el dataset Social Network Ads, donde vamos predecir si alguien va a realizar una compra. \n",
    "\n",
    "- Variable de Respuesta: Purchased (1/0)\n",
    "- Variables Independientes: Gender (Male/Female), Age (numerica), EstimatedSalary (numerica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total de rows en el dataset: 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  EstimatedSalary\n",
       "0       1   19            19000\n",
       "1       1   35            20000\n",
       "2       0   26            43000\n",
       "3       0   27            57000\n",
       "4       1   19            76000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data/Social_Network_Ads.csv\")\n",
    "\n",
    "y = np.array(data[\"Purchased\"]).reshape(-1,1)\n",
    "\n",
    "data.drop(columns=['User ID','Purchased'],axis=1,inplace=True)\n",
    "data.head()\n",
    "\n",
    "data[\"Gender\"] =  np.array([1 if y == 'Male' else 0 for y in data[\"Gender\"]])\n",
    "\n",
    "X = data\n",
    "\n",
    "print(\"total de rows en el dataset:\", X.shape[0])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del set de Entrenamiento (320, 3)\n",
      "Tamaño del set de Pruebas (80, 3)\n"
     ]
    }
   ],
   "source": [
    "# seleccion de muestra aleatoria con SkLearn (ratio 80/20)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"Tamaño del set de Entrenamiento\", X_train.shape)\n",
    "print(\"Tamaño del set de Pruebas\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud de la prediccion (Train): 0.640625\n",
      "Exactitud de la prediccion (Test): 0.65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prueba con Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# seleccionamos la particion de entrenamiento, para entrenar el modelo\n",
    "model = LogisticRegression(random_state=0).fit(X_train, y_train.reshape(-1))\n",
    "\n",
    "# probabilidad promedio del subset.\n",
    "acc_train = model.score(X_train, y_train.reshape(-1))\n",
    "acc_test = model.score(X_test, y_test.reshape(-1))\n",
    "\n",
    "print(\"Exactitud de la prediccion (Train):\", acc_train)\n",
    "print(\"Exactitud de la prediccion (Test):\", acc_test)\n",
    "\n",
    "model.predict([[0,35,200000]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación Cruzada (Cross-Validation)\n",
    "\n",
    "Validación cruzada es la técnica de evaluación de modelos de ML donde se busca obtener varias muestras del training set y del test set de un mismo dataset. A diferencia de la tecnica de selección aleatoria, aquí se pueden particionar el test-set y el training set multiples veces con el objetivo de obtener un  rendimiento promedio.\n",
    "\n",
    "Existen diferentes alternativas para realizar esto:\n",
    "\n",
    "- **LOOCV** (Leave-one-out Cross-Validation): el test set se compone solamente de un row (1) y el training set de el resto de los datos. Esto se repite n cantidad de veces y se promedian al final las exactitudes reportadas. \n",
    "- **K-Fold CV** (K-Fold Cross-Validation): Esta técnica es menos exhaustiva que LOOCV y se particiona el dataset en K test-sets. Por ejemplo, si usamos 10-Fold CV, se particiona el dataset en 10 partes distintas, donde cada parte sirve de test-set y el resto de los datos de training set. Esto permite probar 10 configuraciones de remuestreo diferentes, pero sin tener problemas de rendimiento como en el caso de LOOCV. Se dice que LOOCV es K-Fold CV cuando K=N\n",
    "\n",
    "ejemplo de K-Fold CV (k=4):\n",
    "\n",
    "<img src=\"img/cv.png\"/>\n",
    "\n",
    "Nuestra recomendación es que se use K = 5, 10 o 20 según la cantidad de datos. \n",
    "\n",
    "Vamos a utilizar 10-fold CV con nuestro dataset de Social Network Ads: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LogisticRegression(random_state=0)\n",
    "scores = cross_val_score(model, X, y.reshape(-1), cv=10)\n",
    "\n",
    "print(\"Exactitud de cada particion:\", scores)\n",
    "print(\"Exactitud Promedio:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap\n",
    "\n",
    "El método bootstrap es una técnica estadística para estimar cantidades sobre una población promediando estimaciones de múltiples muestras de datos pequeños.\n",
    "\n",
    "Como escoger la muestra:\n",
    "- Determine el tamano de la muestra = Tm\n",
    "- Mientras n < Tm\n",
    "    - Seleccione un row aleatorio del dataset\n",
    "    - agreguelo a la muestra\n",
    "\n",
    "Los elementos que queden fuera de la muestra se conocen como \"ejemplos fuera de la muestra\" (OOB - Out-of-Bag Samples)\n",
    "\n",
    "Tamano del Sample:  entre 50% y 80% del dataset, esto puede variar dependiendo de tamano.\n",
    "Repeticiones: de 20 a 50, sin embargo entre mas repeticiones, mejor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se usa el metodo resample para seleccionar la muestra\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv(\"data/Social_Network_Ads.csv\")\n",
    "data.drop(columns=['User ID'],axis=1,inplace=True)\n",
    "data[\"Gender\"] =  np.array([1 if y == 'Male' else 0 for y in data[\"Gender\"]])\n",
    "\n",
    "# tamano de la  muestra (50%)\n",
    "Tm = int(data.shape[0]/2) \n",
    "# cuantas  veces vamos a repetir el proceso \n",
    "reps = 20\n",
    "#\n",
    "scores = np.array([]);\n",
    "\n",
    "for i in np.arange(1,reps):\n",
    "    # seleccion de los samples\n",
    "    boot = resample(data, replace=False, n_samples=Tm)\n",
    "    oob = data.drop(boot.index, axis=0)\n",
    "    y_train = boot[\"Purchased\"]\n",
    "    X_train = boot.loc[:, boot.columns != 'Purchased']\n",
    "    y_test = oob[\"Purchased\"]\n",
    "    X_test = oob.loc[:, oob.columns != 'Purchased']\n",
    "\n",
    "    # seleccionamos la particion de entrenamiento, para entrenar el modelo\n",
    "    model = LogisticRegression(random_state=0).fit(X_train, np.array(y_train).reshape(-1))\n",
    "\n",
    "    # probabilidad promedio del subset.\n",
    "    score = model.score(X_test, np.array(y_test).reshape(-1))\n",
    "    scores = np.append(scores, score)\n",
    "\n",
    "print(\"Exactitud Promedio:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

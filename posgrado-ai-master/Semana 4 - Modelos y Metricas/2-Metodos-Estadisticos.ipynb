{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos Estadísticos\n",
    "\n",
    "Las medidas probabilísticas implican calificar analíticamente un modelo candidato utilizando tanto su desempeño en el conjunto de datos de entrenamiento como en la complejidad del modelo.\n",
    "\n",
    "Se sabe que el error de entrenamiento tiene un sesgo optimista (por overfitting) y, por lo tanto, no es una buena base para elegir un modelo. El rendimiento se puede penalizar en función de cuán optimista se cree que es el error de entrenamiento. Por lo general, esto se logra mediante métodos específicos de algoritmos, a menudo lineales, que penalizan la puntuación en función de la **complejidad del modelo**.\n",
    "\n",
    "Existen varias tecnicas probabilisticas para la seleccion de modelos, dos de las mas populares son:\n",
    "- AIC (Akaike Information Criterion)\n",
    "- BIC (Bayesian Information Criterio)\n",
    "\n",
    "Existen dos criterios principales a utilizar cuando evaluamos modelos:\n",
    "- Rendimiento del modelo: Rendimiento del modelo despues de entrenarlo con el set de entrenamiento.\n",
    "- Complejidad del modelo: Grados de libertad o cantidad de parametros del modelo. Se asume que entre más parámetros, más complejidad existe en el modelo.\n",
    "\n",
    "A continuación, vamos a revisar cómo podemos implementar estas técnicas en la selección de nuestros modelos de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación de Probabilidad Máxima\n",
    "\n",
    "Cada estadística se puede calcular utilizando la probabilidad logarítmica de un modelo y los datos. La probabilidad logarítmica proviene de la estimación de probabilidad máxima (Maximum Likelihood Estimation), una técnica para encontrar u optimizar los parámetros de un modelo en respuesta a un conjunto de datos de entrenamiento.\n",
    "\n",
    "En la estimación de probabilidad máxima, deseamos maximizar la probabilidad condicional de observar los datos (X) dada una distribución de probabilidad específica y sus parámetros (beta), expresados formalmente como:\n",
    "\n",
    "- $P(X|\\beta)$ donde $X$ es la probabilidad conjunta de todos los datos $x_i$ o bien,\n",
    "- $P(x_1 + x_2,+...+,x_n|\\beta) = \\sum log(P(x_i|\\beta))$\n",
    "\n",
    "<img src=\"img/frebay.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC (Akaike Information Criterion)\n",
    "\n",
    "Lleva el nombre del desarrollador del método, Hirotugu Akaike, y stiene una base en la teoría de la información y la inferencia frecuentista.\n",
    "\n",
    "la formula de AIC varia segun el algoritmo:\n",
    "\n",
    "- $regresion Logistica: AIC = -2/n * log(MLE) + 2 * k/n$\n",
    "- $regresion Lineal: AIC = n * log(MLE) + 2 * k$\n",
    "\n",
    "Donde:\n",
    "- n: número de rows en el training set\n",
    "- MLE: estimación de máxima verosimilitud (logarítmica) [maximum likelihood estimation]\n",
    "- k: número de parámetros  en el modelo (features)\n",
    "\n",
    "Una vez que se calcula el AIC, para varios modelos, se escoje el modelo con el AIC mas pequeno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import log\n",
    "\n",
    "# generar un dataset random con 2 variables\n",
    "X, y = make_regression(n_samples=100, n_features=2, noise=0.1)\n",
    "\n",
    "# entrenar el modelo\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# realizar la prediccion sobre el set de entrenamiento\n",
    "y_prima = model.predict(X)\n",
    "\n",
    "# calculate the error\n",
    "MSE = mean_squared_error(y, y_prima)\n",
    "print('MSE: %.3f' % MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC: -447.6491776984325 MSE: 0.010710917003088854 Parametros: 3\n"
     ]
    }
   ],
   "source": [
    "# parametros del modelo\n",
    "k = len(model.coef_) + 1\n",
    "\n",
    "# cantidad de datos\n",
    "n = X.shape[0]\n",
    "\n",
    "# EPM es el MSE!\n",
    "def estimar_aic(n, mle, k):\n",
    "    aic = n * log(mle) + 2 * k\n",
    "    return aic\n",
    "\n",
    "aic_score = estimar_aic(n,MSE,k)\n",
    "\n",
    "print(\"AIC:\", aic_score, \"MSE:\",MSE, \"Parametros:\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO IMPLEMENTE AIC PARA LOGISTIC REGRESSION\n",
    "# Para el siguiente dataset\n",
    "\n",
    "# Nuestro dataset de aprobación de exámenes dadas las horas de estudio, sueño y repeticiones\n",
    "horas_estudio = [5, 4, 1, 1, 1, 2, 3, 3, 2, 0, 3, 3, 2, 3, 2, 3, 1, 5, 4, 4, 3, 4, 2, 4, 3, 3, 6, 4, 4, 5, 3, 4, 3, 2, 6, 2, 4, 4, 1, 5, 3, 3, 5, 7, 4, 3, 5, 2, 3, 5, 3, 4, 3, 3, 1, 3, 6, 0, 4, 3, 7, 2, 5, 3, 3, 4, 3, 1, 5, 4, 1, 4, 3, 1, 2, 4, 2, 2, 2, 2, 4, 3, 3, 1, 4, 2, 1, 0, 4, 4, 3, 3, 4, 6, 5, 3, 2, 2, 6, 6]\n",
    "horas_sueno = [4, 4, 5, 5, 4, 6, 7, 7, 5, 8, 5, 7, 7, 7, 7, 7, 4, 8, 4, 8, 6, 8, 5, 4, 5, 5, 7, 4, 6, 8, 6, 4, 7, 4, 5, 7, 7, 4, 6, 6, 5, 6, 7, 6, 4, 8, 7, 4, 4, 6, 5, 8, 6, 8, 4, 5, 4, 6, 8, 5, 6, 6, 5, 6, 4, 8, 4, 6, 5, 7, 5, 6, 7, 7, 8, 4, 4, 6, 8, 6, 4, 6, 5, 5, 5, 4, 4, 7, 8, 5, 4, 8, 5, 6, 5, 6, 7, 7, 4, 5]\n",
    "repeticiones = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "resultado_examen = ['APROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'REPROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'APROBADO', 'REPROBADO', 'REPROBADO', 'APROBADO', 'APROBADO']\n",
    "\n",
    "# TODO: Aqui su codigo para estimar AIC con LogReg\n",
    "# verifique el cambio de AIC con mas o menos variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC (Bayesian Information Criterion)\n",
    "\n",
    "Recibe el nombre del campo de estudio del que se derivó: probabilidad e inferencias bayesianas. Al igual que AIC, es apropiado para modelos que se ajustan al marco de MLE.\n",
    "\n",
    "la formula de BIC varia segun el algoritmo:\n",
    "\n",
    "- $Regresion Logistica: BIC = -2 * log(MLE) + log(n) * k$\n",
    "- $Regresion Lineal: BIC = n * log(MLE) + k * log(n) $\n",
    "\n",
    "El BIC penaliza más al modelo por su complejidad, lo que significa que los modelos más complejos tendrán una puntuación peor (mayor) y, a su vez, será menos probable que sean seleccionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPM es el MSE!\n",
    "def estimar_bic(n, mle, k):\n",
    "    bic = n * log(mle) + k * log(n)\n",
    "    return bic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO IMPLEMENTE BIC PARA LOGISTIC REGRESSION\n",
    "# Para el mismo dataset de las horas de estudio.\n",
    "\n",
    "# TODO: Aqui su codigo para estimar BIC con LogReg\n",
    "# verifique el cambio de BIC con mas o menos variables\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "arr_x = np.array((horas_estudio, horas_sueno, repeticiones)).T\n",
    "\n",
    "# En cuanto a la salida, scikit-learn se encarga de todas las codificaciones binarias\n",
    "arr_y = np.array(resultado_examen)\n",
    "\n",
    "encoder.fit(arr_y)\n",
    "arr_y=encoder.transform(arr_y)\n",
    "\n",
    "exame_model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "exame_model.fit(arr_x, arr_y)\n",
    "\n",
    "# realizar la prediccion sobre el set de entrenamiento\n",
    "y_prima_examen = exame_model.predict(arr_x)\n",
    "\n",
    "# calculate the error\n",
    "MSE_EXAM = mean_squared_error(arr_y, y_prima_examen)\n",
    "\n",
    "k = len(exame_model.coef_) + 1\n",
    "\n",
    "# cantidad de datos\n",
    "n = arr_x.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC: -447.6491776984325 MSE: 0.08 Parametros: 2\n",
      "BIC: -444.4388373264563 MSE: 0.08 Parametros: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bic_score = estimar_bic(n,MSE,k)\n",
    "\n",
    "print(\"AIC:\", aic_score, \"MSE:\",MSE_EXAM, \"Parametros:\",k)\n",
    "print(\"BIC:\", bic_score, \"MSE:\",MSE_EXAM, \"Parametros:\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
